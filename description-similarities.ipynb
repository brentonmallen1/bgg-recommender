{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boardgame Similarities using Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/brentonmallen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/brentonmallen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/brentonmallen/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import boardgamegeek as bgg\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datasketch import MinHash, MinHashLSH, MinHashLSHForest\n",
    "from sklearn.externals import joblib\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus.reader.wordnet import ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = stopwords.words('english') + list(punctuation)\n",
    "# add board game specific ones\n",
    "boardgame_stopwords = [\n",
    "    'board',\n",
    "    'boardgame',\n",
    "    'boardgames',\n",
    "    'player',\n",
    "    'play',\n",
    "    'played',\n",
    "    'rule',\n",
    "    'rulebook',\n",
    "    'expansion',\n",
    "    'game',\n",
    "    'point',\n",
    "    'victory',\n",
    "    'win',\n",
    "    'piece',\n",
    "    'turn',\n",
    "    'round',\n",
    "    'point',\n",
    "    'score'\n",
    "    \n",
    "]\n",
    "\n",
    "STOPWORDS.extend(boardgame_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "\n",
    "PATTERN = re.compile(\"(|)\")\n",
    "\n",
    "def process_description(desc,\n",
    "                        stop_words=stopwords.words('english'),\n",
    "                        tokenize=True,\n",
    "                        regex_pattern=None):\n",
    "    \n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    stmmr = SnowballStemmer('english', ignore_stopwords=True)\n",
    "        \n",
    "    # remove publisher description, newlines and strip\n",
    "    processed_desc = (desc.\n",
    "                      replace(\"Description from the publisher:\", \"\").\n",
    "                      replace('\\n', ' ').\n",
    "                      strip()\n",
    "                     )\n",
    "    processed_desc = re.sub(regex_pattern, \"\", processed_desc)\n",
    "    # remove puctuation\n",
    "    table = str.maketrans('', '', punctuation)\n",
    "    processed_desc = [w.translate(table) for w in processed_desc]\n",
    "    processed_desc = \"\".join(processed_desc).split(' ')\n",
    "    # lower case everything\n",
    "    processed_desc = [w.lower() for w in processed_desc]\n",
    "    # lemmatize words\n",
    "    processed_desc = [lmtzr.lemmatize(w) for w in processed_desc]\n",
    "    # remove stop words\n",
    "    processed_desc = [w for w in processed_desc if w not in stop_words and not w.isdigit()]\n",
    "    # stem words\n",
    "#     processed_desc = [stmmr.stem(w) for w in processed_desc]\n",
    "    if tokenize:\n",
    "        return list(set(processed_desc))\n",
    "    else:\n",
    "        return \" \".join(processed_desc)\n",
    "    \n",
    "    \n",
    "def process_tokens(row):\n",
    "    output_tokens = []\n",
    "    output_tokens.extend(process_description(row['description']))\n",
    "    output_tokens.extend(row['categories'])\n",
    "    output_tokens.extend(row['mechanics'])\n",
    "    output_tokens.extend(row['families'])\n",
    "    output_tokens.extend(row['designers'])\n",
    "    return output_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Game Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'game_data-20180627.gz'\n",
    "game_data = joblib.load(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_partial = partial(process_description,\n",
    "                          regex_pattern=PATTERN,\n",
    "                          tokenize=False,\n",
    "                          stop_words = STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data['_desc'] = game_data['description'].apply(process_partial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description Topic Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 250\n",
    "n_components = 20  # number of topics\n",
    "n_top_words = 20\n",
    "tf_vectorizer = CountVectorizer(max_df=0.99, min_df=.01,\n",
    "                                max_features=n_features,\n",
    "                                analyzer='word',\n",
    "                                stop_words=STOPWORDS,\n",
    "                                ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.637s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "tf = tf_vectorizer.fit_transform(game_data['_desc'])\n",
    "print(\"done in %0.3fs.\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=4917 and n_features=250...\n",
      "done in 9.796s.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (tf.shape[0], n_features))\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0\n",
    "                                )\n",
    "\n",
    "t0 = time.time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: character king dragon location role take one ability new adventure power house special weapon gold set different includes series face\n",
      "Topic #1: de treasure island room gold find secret must try help sea way ha order house around end collect course many\n",
      "Topic #2: tile train placed line two place new one type placing set number level end ha also may four series bonus\n",
      "Topic #3: war battle army unit system combat force command two side map one world scenario series also front event first ha\n",
      "Topic #4: new set edition master word adventure time book box also includes youll need even feature original one make find hero\n",
      "Topic #5: card deck hand one ha two draw take end set first start playing three also number new value face table\n",
      "Topic #6: phase influence land action gain take end may power one control region next time choose year people use must many\n",
      "Topic #7: hero monster dungeon animal level treasure one take ha different ability must new card two fight need start first four\n",
      "Topic #8: building resource build worker action town order block take one end new use city work need different available type place\n",
      "Topic #9: city good money company new market family trade end one get house make buy take action must build ha time\n",
      "Topic #10: one move color number two place ha space token action three end take first four must row opponent five placed\n",
      "Topic #11: world race new base strategy unique move different skill time set around movement together experience ha also track one system\n",
      "Topic #12: ship space planet sea system must action one high begin take well ha reach movement also two much command move\n",
      "Topic #13: mission leader plan weapon group enemy series take combat way campaign different complete tactical youll role help new need find\n",
      "Topic #14: map scenario german one counter campaign scale two time battle hex series hour unit day per wa great full cover\n",
      "Topic #15: air force feature first war german take role allows end world weapon edition year combat us simple unique together system\n",
      "Topic #16: dice team roll die one get make card ha take must two use action best time three ability first every\n",
      "Topic #17: wa one ha track time event version different also marker get many first scoring bonus end take way thing card\n",
      "Topic #18: power control attack enemy fight opponent battle powerful area must use ability force ha new strategy special unique weapon life\n",
      "Topic #19: empire faction miniature field control ha war set new one take great four age special across two ability world build\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pandemic several virulent disease broken simultaneously world diseasefighting specialist whose mission treat disease hotspot researching cure four plague get hand  depicts several major population center earth use four action travel city treat infected populace discover cure build research station deck card provides ability sprinkled throughout deck epidemic card accelerate intensify disease activity second separate deck card control normal spread infection  taking unique role within team must plan strategy mesh specialist strength order conquer disease example operation expert build research station needed find cure disease allow greater mobility city scientist need four card particular disease cure instead normal five—but disease spreading quickly time running one disease spread beyond recovery much time elapses lose cure four disease  edition pandemic includes two new characters—the contingency planner quarantine specialist—not available earlier edition  pandemic first pandemic series']"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = 'Pandemic'\n",
    "game_data[game_data.title == g]['_desc'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = lda.transform(tf_vectorizer.transform(game_data[game_data.title == g]['_desc']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adventure allows additional another around attempt also allow age available add attack along ability area air action across animal army'"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([tf_vectorizer.get_feature_names()[i] for i in a[0].argsort()[::-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0009434 , 0.0009434 , 0.0009434 , 0.0009434 , 0.16457074,\n",
       "       0.30235093, 0.0009434 , 0.0009434 , 0.0009434 , 0.24493383,\n",
       "       0.0009434 , 0.0009434 , 0.0009434 , 0.10300961, 0.0009434 ,\n",
       "       0.0009434 , 0.10216844, 0.0009434 , 0.06975891, 0.0009434 ])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
